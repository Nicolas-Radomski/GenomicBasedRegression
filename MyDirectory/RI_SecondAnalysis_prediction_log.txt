###########################
######### context #########
###########################
The scikit-learn (sklearn)-based Python workflow independently supports both modeling (i.e., training and testing) and prediction (i.e., using a pre-built model), and implements 5 feature selection methods, 19 model regressors, hyperparameter tuning, performance metric computation, feature and permutation importance analyses, prediction interval estimation, execution monitoring via progress bars, and parallel processing.
###########################
######## reference ########
###########################
An article might potentially be published in the future.
###########################
###### repositories  ######
###########################
Please cite:
 GitHub (https://github.com/Nicolas-Radomski/GenomicBasedRegression),
 Docker Hub (https://hub.docker.com/r/nicolasradomski/genomicbasedregression),
 and/or Anaconda Hub (https://anaconda.org/nicolasradomski/genomicbasedregression).
###########################
#### acknowledgements  ####
###########################
Many thanks to Andrea De Ruvo, Adriano Di Pasquale and ChatGPT for the insightful discussions that helped improve the algorithm.
###########################
######## versions  ########
###########################
GenomicBasedRegression: 1.3.0 (released in December 2025)
python: 3.12
argparse: 1.1
scipy: 1.16.0
pandas: 2.2.2
sklearn: 1.5.2
pickle: 4.0
catboost: 1.2.8
lightgbm: 4.6.0
xgboost: 2.1.3
numpy: 1.26.4
joblib: 1.5.1
tqdm: 4.67.1
tqdm-joblib: 0.0.4
###########################
######## arguments  #######
###########################
subcommand: prediction
inputpath_mutations: genomic_profils_for_prediction.tsv
inputpath_features: MyDirectory/RI_FirstAnalysis_features.obj
inputpath_feature_encoder: MyDirectory/RI_FirstAnalysis_feature_encoder.obj
inputpath_calibration_features: MyDirectory/RI_FirstAnalysis_calibration_features.obj
inputpath_calibration_targets: MyDirectory/RI_FirstAnalysis_calibration_targets.obj
inputpath_model: MyDirectory/RI_FirstAnalysis_model.obj
alpha: 0.05
outputpath: MyDirectory
prefix: RI_SecondAnalysis
digits: 6
debug: 0
warnings: False
nocheck: False
###########################
######### checks  #########
###########################
The traceback level was set to 0
The warnings were ignored
The recommended versions of Python and packages were properly controlled
The prediction subcommand was used
The minimum required number of samples in the dataset (i.e., >= 1) and the expected number of columns (i.e., >= 3) in the input file of mutations were properly controlled (i.e., 20 and 12, respectively)
The input tested mutations include all features required by the trained one-hot encoder
The following unexpected features in the input tested mutations will be ignored for one-hot encoding: ['Locus_11']
The encoded features between training and prediction datasets were confirmed as identical
The 10 provided features were one-hot encoded into 80 encoded features
The pipeline expected 50 one-hot encoded features to perform prediction
The pipeline components of the provided best model were properly recognized: Pipeline(steps=[('feature_selection', SelectKBest(k=50, score_func=<function mutual_info_regression at 0x7fd2fba20540>)), ('model', Ridge(alpha=0.01, max_iter=1000))])
The one-hot encoded prediction matrix was reindexed and aligned to match the exact feature names and order expected by the trained pipeline
The prediction intervals (i.e., 95.0%) were calculated using a significance level of alpha = 0.05
The output directory already existed
###########################
####### execution  ########
###########################
The script started on 2025-12-16 16:18:56.088014
The script stoped on 2025-12-16 16:18:56.113050
The script lasted 0 days, 0 hrs, 0 mins and 0.03 secs (i.e., 0.03 secs in total)
###########################
###### output  files ######
###########################
MyDirectory/RI_SecondAnalysis_prediction.tsv
MyDirectory/RI_SecondAnalysis_prediction_log.txt
###########################
### prediction  dataset ###
###########################
 sample  prediction     lower     upper
S2.1.01   29.214569 22.001794 36.427344
S2.1.02   29.676610 22.463835 36.889386
S2.1.03   20.838448 13.625673 28.051223
S2.1.04   44.155473 36.942698 51.368248
S2.1.05   23.188286 15.975511 30.401061
S2.1.06   20.486085 13.273310 27.698861
S2.1.07   45.632519 38.419743 52.845294
S2.1.08   21.181166 13.968391 28.393941
S2.1.09   56.317350 49.104575 63.530125
S2.1.10   46.004157 38.791382 53.216932
S2.1.11   21.070895 13.858119 28.283670
S2.1.12   50.695608 43.482833 57.908383
S2.1.13   22.094186 14.881411 29.306961
S2.1.14   22.796487 15.583712 30.009262
S2.1.15   11.802778  4.590003 19.015553
S2.1.16   23.825929 16.613153 31.038704
S2.1.17   25.364710 18.151934 32.577485
S2.1.18    7.205353 -0.007423 14.418128
S2.1.19    2.599784 -4.612991  9.812559
S2.1.20    3.145235 -4.067540 10.358010
Note: Up to 20 results are displayed in the log for monitoring purposes, while the full set of results is available in the output files. 
Lower and upper correspond to the range of the prediction intervals. 
