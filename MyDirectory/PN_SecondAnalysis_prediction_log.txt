###########################
######### context #########
###########################
The scikit-learn (sklearn)-based Python workflow independently supports both modeling (i.e., training and testing) and prediction (i.e., using a pre-built model), and implements 5 feature selection methods, 19 model regressors, hyperparameter tuning, performance metric computation, feature and permutation importance analyses, prediction interval estimation, execution monitoring via progress bars, and parallel processing.
###########################
######## reference ########
###########################
An article might potentially be published in the future.
###########################
###### repositories  ######
###########################
Please cite:
 GitHub (https://github.com/Nicolas-Radomski/GenomicBasedRegression),
 Docker Hub (https://hub.docker.com/r/nicolasradomski/genomicbasedregression),
 and/or Anaconda Hub (https://anaconda.org/nicolasradomski/genomicbasedregression).
###########################
#### acknowledgements  ####
###########################
Many thanks to Andrea De Ruvo, Adriano Di Pasquale and ChatGPT for the insightful discussions that helped improve the algorithm.
###########################
######## versions  ########
###########################
GenomicBasedRegression: 1.3.0 (released in December 2025)
python: 3.12
argparse: 1.1
scipy: 1.16.0
pandas: 2.2.2
sklearn: 1.5.2
pickle: 4.0
catboost: 1.2.8
lightgbm: 4.6.0
xgboost: 2.1.3
numpy: 1.26.4
joblib: 1.5.1
tqdm: 4.67.1
tqdm-joblib: 0.0.4
###########################
######## arguments  #######
###########################
subcommand: prediction
inputpath_mutations: genomic_profils_for_prediction.tsv
inputpath_features: MyDirectory/PN_FirstAnalysis_features.obj
inputpath_feature_encoder: MyDirectory/PN_FirstAnalysis_feature_encoder.obj
inputpath_calibration_features: MyDirectory/PN_FirstAnalysis_calibration_features.obj
inputpath_calibration_targets: MyDirectory/PN_FirstAnalysis_calibration_targets.obj
inputpath_model: MyDirectory/PN_FirstAnalysis_model.obj
alpha: 0.05
outputpath: MyDirectory
prefix: PN_SecondAnalysis
digits: 6
debug: 0
warnings: False
nocheck: False
###########################
######### checks  #########
###########################
The traceback level was set to 0
The warnings were ignored
The recommended versions of Python and packages were properly controlled
The prediction subcommand was used
The minimum required number of samples in the dataset (i.e., >= 1) and the expected number of columns (i.e., >= 3) in the input file of mutations were properly controlled (i.e., 20 and 12, respectively)
The input tested mutations include all features required by the trained one-hot encoder
The following unexpected features in the input tested mutations will be ignored for one-hot encoding: ['Locus_11']
The encoded features between training and prediction datasets were confirmed as identical
The 10 provided features were one-hot encoded into 80 encoded features
The pipeline expected 25 one-hot encoded features to perform prediction
The pipeline components of the provided best model were properly recognized: Pipeline(steps=[('feature_selection', SelectKBest(k=25, score_func=<function mutual_info_regression at 0x7f0e35218540>)), ('model', LinearRegression())])
The one-hot encoded prediction matrix was reindexed and aligned to match the exact feature names and order expected by the trained pipeline
The prediction intervals (i.e., 95.0%) were calculated using a significance level of alpha = 0.05
The output directory already existed
###########################
####### execution  ########
###########################
The script started on 2025-12-16 16:17:58.155282
The script stoped on 2025-12-16 16:17:58.179092
The script lasted 0 days, 0 hrs, 0 mins and 0.02 secs (i.e., 0.02 secs in total)
###########################
###### output  files ######
###########################
MyDirectory/PN_SecondAnalysis_prediction.tsv
MyDirectory/PN_SecondAnalysis_prediction_log.txt
###########################
### prediction  dataset ###
###########################
 sample  prediction     lower     upper
S2.1.01   36.095004 29.578263 42.611745
S2.1.02   36.095004 29.578263 42.611745
S2.1.03   21.236181 14.719440 27.752923
S2.1.04   46.528907 40.012166 53.045648
S2.1.05   23.452268 16.935527 29.969010
S2.1.06   21.256277 14.739536 27.773019
S2.1.07   47.739988 41.223247 54.256730
S2.1.08   21.151234 14.634493 27.667976
S2.1.09   50.918179 44.401437 57.434920
S2.1.10   45.999972 39.483230 52.516713
S2.1.11   19.196139 12.679398 25.712880
S2.1.12   51.489952 44.973211 58.006693
S2.1.13   26.333133 19.816392 32.849874
S2.1.14    4.424381 -2.092360 10.941123
S2.1.15    3.098562 -3.418179  9.615303
S2.1.16    4.711598 -1.805143 11.228339
S2.1.17    6.666694  0.149953 13.183435
S2.1.18    7.106382  0.589641 13.623124
S2.1.19    3.106396 -3.410345  9.623137
S2.1.20    3.098562 -3.418179  9.615303
Note: Up to 20 results are displayed in the log for monitoring purposes, while the full set of results is available in the output files. 
Lower and upper correspond to the range of the prediction intervals. 
