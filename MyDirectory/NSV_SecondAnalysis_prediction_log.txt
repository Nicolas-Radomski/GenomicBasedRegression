###########################
######### context #########
###########################
The scikit-learn (sklearn)-based Python workflow independently supports both modeling (i.e., training and testing) and prediction (i.e., using a pre-built model), and implements 5 feature selection methods, 19 model regressors, hyperparameter tuning, performance metric computation, feature and permutation importance analyses, prediction interval estimation, execution monitoring via progress bars, and parallel processing.
###########################
######## reference ########
###########################
An article might potentially be published in the future.
###########################
###### repositories  ######
###########################
Please cite:
 GitHub (https://github.com/Nicolas-Radomski/GenomicBasedRegression),
 Docker Hub (https://hub.docker.com/r/nicolasradomski/genomicbasedregression),
 and/or Anaconda Hub (https://anaconda.org/nicolasradomski/genomicbasedregression).
###########################
#### acknowledgements  ####
###########################
Many thanks to Andrea De Ruvo, Adriano Di Pasquale and ChatGPT for the insightful discussions that helped improve the algorithm.
###########################
######## versions  ########
###########################
GenomicBasedRegression: 1.3.0 (released in December 2025)
python: 3.12
argparse: 1.1
scipy: 1.16.0
pandas: 2.2.2
sklearn: 1.5.2
pickle: 4.0
catboost: 1.2.8
lightgbm: 4.6.0
xgboost: 2.1.3
numpy: 1.26.4
joblib: 1.5.1
tqdm: 4.67.1
tqdm-joblib: 0.0.4
###########################
######## arguments  #######
###########################
subcommand: prediction
inputpath_mutations: genomic_profils_for_prediction.tsv
inputpath_features: MyDirectory/NSV_FirstAnalysis_features.obj
inputpath_feature_encoder: MyDirectory/NSV_FirstAnalysis_feature_encoder.obj
inputpath_calibration_features: MyDirectory/NSV_FirstAnalysis_calibration_features.obj
inputpath_calibration_targets: MyDirectory/NSV_FirstAnalysis_calibration_targets.obj
inputpath_model: MyDirectory/NSV_FirstAnalysis_model.obj
alpha: 0.05
outputpath: MyDirectory
prefix: NSV_SecondAnalysis
digits: 6
debug: 0
warnings: False
nocheck: False
###########################
######### checks  #########
###########################
The traceback level was set to 0
The warnings were ignored
The recommended versions of Python and packages were properly controlled
The prediction subcommand was used
The minimum required number of samples in the dataset (i.e., >= 1) and the expected number of columns (i.e., >= 3) in the input file of mutations were properly controlled (i.e., 20 and 12, respectively)
The input tested mutations include all features required by the trained one-hot encoder
The following unexpected features in the input tested mutations will be ignored for one-hot encoding: ['Locus_11']
The encoded features between training and prediction datasets were confirmed as identical
The 10 provided features were one-hot encoded into 80 encoded features
The pipeline expected 50 one-hot encoded features to perform prediction
The pipeline components of the provided best model were properly recognized: Pipeline(steps=[('feature_selection', SelectKBest(k=50, score_func=<function mutual_info_regression at 0x7f4bd5ad8540>)), ('model', NuSVR(C=10, kernel='linear', max_iter=2000))])
The one-hot encoded prediction matrix was reindexed and aligned to match the exact feature names and order expected by the trained pipeline
The prediction intervals (i.e., 95.0%) were calculated using a significance level of alpha = 0.05
The output directory already existed
###########################
####### execution  ########
###########################
The script started on 2025-12-16 16:17:40.775126
The script stoped on 2025-12-16 16:17:40.799196
The script lasted 0 days, 0 hrs, 0 mins and 0.02 secs (i.e., 0.02 secs in total)
###########################
###### output  files ######
###########################
MyDirectory/NSV_SecondAnalysis_prediction.tsv
MyDirectory/NSV_SecondAnalysis_prediction_log.txt
###########################
### prediction  dataset ###
###########################
 sample  prediction     lower     upper
S2.1.01   28.943115 19.893740 37.992490
S2.1.02   29.983281 20.933906 39.032656
S2.1.03   17.610027  8.560652 26.659402
S2.1.04   45.610394 36.561019 54.659769
S2.1.05   17.214383  8.165008 26.263759
S2.1.06   17.613230  8.563855 26.662606
S2.1.07   37.898307 28.848932 46.947682
S2.1.08   18.613352  9.563977 27.662727
S2.1.09   58.989832 49.940457 68.039207
S2.1.10   45.998163 36.948787 55.047538
S2.1.11   16.613283  7.563908 25.662658
S2.1.12   48.123274 39.073899 57.172649
S2.1.13   17.977696  8.928320 27.027071
S2.1.14   20.724192 11.674817 29.773567
S2.1.15    9.670398  0.621023 18.719773
S2.1.16   21.687440 12.638065 30.736816
S2.1.17   22.695215 13.645840 31.744590
S2.1.18    9.761785  0.712410 18.811160
S2.1.19    2.022463 -7.026912 11.071838
S2.1.20    3.970964 -5.078412 13.020339
Note: Up to 20 results are displayed in the log for monitoring purposes, while the full set of results is available in the output files. 
Lower and upper correspond to the range of the prediction intervals. 
