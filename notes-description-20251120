conda update --all
conda --version # conda 25.7.0
conda create --name env_conda_GenomicBasedRegression_1.2.0 python=3.12
conda activate env_conda_GenomicBasedRegression_1.2.0
python --version # Python Python 3.12.12
conda install -c conda-forge mamba=2.0.5
mamba install -c conda-forge catboost==1.2.8
mamba install -c conda-forge pandas==2.2.2
mamba install -c conda-forge xgboost==2.1.3
mamba install -c conda-forge lightgbm==4.6.0
# TRASH mamba install -c nicolasradomski boruta==0.4.3
mamba install -c conda-forge scipy==1.16.0
mamba install -c conda-forge scikit-learn==1.5.2
mamba install -c conda-forge numpy==1.26.4
mamba install -c conda-forge joblib==1.5.1
mamba install -c conda-forge tqdm==4.67.1
mamba install -c nicolasradomski tqdm-joblib=0.0.4
conda list -n env_conda_GenomicBasedRegression_1.2.0
conda deactivate # after usage

python GenomicBasedRegression.py

Last modification from GenomicBasedClassification (version 1.2.0)

DONE-ok- library versions harmonisation
DONE-ok- harmonize library accronyme
DONE-ok harmonize "retrieve the combinations of tested parameters and corresponding scores"
DONE-ok- argument controls (--debug is missing in regression and must be added)
DONE-ok- refer to guidelines to set parameters of classifiers => readme
DONE-ok- add conda version and python conda version in readme
DONE-ok- check than the new count method is independant of class number
DONE-ok- add second execution time
DONE-ok- check reference, repositories, acknowleadgment
DONE-ok- for both (training and testing: check for regression) check "numeric compatibility (astype(np.float32)) with upstream encoding (sparse_output=False) and efficiency (float32 dtype)" add downstream variables 
for classification: X_train_encoded_float32, X_test_encoded_float32, y_train_series ,y_test_series
for regression: X_train_encoded_float32, X_test_encoded_float32, y_train_float32, y_test_float32
DONE-ok- aligne "compute metrics related to grid search CV"
DONE-ok- harmonize "manage minimal limits of samples"
DONE-ok- add functions
DONE-ok- global sklearn config early
DONE-ok- harmonize "check the input file"
DONE-ok- identify if feature selection methods must be before or after OHE => to keep locus-allele in downstream feature importance
DONE-ok- Pass one-hot encoder from “modeling” to “prediction” subcommands rather than encoded features
DONE-ok- check if encoded_classes for the XGB model is properly passed
DONE-ok- Elegant Pipeline() function to pass analytical steps
DONE-ok- Performance metric calculations as functions
DONE-ok- ROC-AUC and /or PR-AUC as performance metric
DONE-ok- Feature selections methods
DONE-ok- Feature permutation (model agnostic but computationally intensive)
DONE-ok-latter Sampling methods
DONE-ok- Potential SHAP (computationally intensive)
DONE-ok- update context after full implementation
DONE-ok- adapt count_selected_features function after implementation of pipeline (might be improve in regression)
DONE-ok- check index are not printed for df (print(count_classes_df.to_string(index=False)) and print(count_classes_df.to_string(index=False), file=log_file))
DONE-ok- check that coloumn nb checking and second column class number checking works well
DONE-ok- print message log traceback before warning (traceback, warnings, version, subcommand)
DONE-ok- check i.e. => i.e., (and e.g. => e.g.,), α => alpha
DONE-ok- check utility of _features.obj output of modelling and INPUTPATH_FEATURES for prediction => importante to controle missing and extra features
DONE-ok- missing message_permutation in log of modelling regression
DONE-ok- permutation importance also from testing => yes to identify potentiel features involved in overfitting (must be added in regression)
DONE-ok- "n_repeats = 10  # default number of permutations per feature" is not necessary for permutation importance during regression
DONE-ok- default NREPEATS = 10 => yes good balance
DONE-ok- add (modeling and prediction) the message_assert_encoded_features (block ## assert identical encoded features between training and testing datasets and ## assert identical encoded features between training and prediction datasets) (must be added in regression)
DONE -ok- keep random_state=42 in every call to permutation_importance to improves debugging and reliability without bias permutation importance (ok for regression, must be done for classification)
DONE-ok- While the progress bars of permutaiton importance (see block below) are systematically and completelly displayed for DT, KNN, LR, SVC and XGB, the progress bars of permutaiton importance for RF are not displayed systematically (left side is progressing: "280it [00:17, 15.72it/s]" but right side is not progression: "0%| | 0/80 [00:00<?, ?it/s]"), and are displayed completelly (both left and right sides are progrssing) from time to time (rarelly) faster than the real execution time (the progress bars are finished while the permutation importance steps are not finished yet). => "fix nested parallelism issues for RandomForest to ensure stable tqdm progress bar during permutation importance"  (must be added for regression)
DONE-ok- not progress bar with one job: When using 2 or more than 2 n_jobs, the progress bars (modelling and permutation importance below) are displayed as expected, while when using one n_jobs, the progress bars are not diplayed properly (stay displaying just :"0%| | 0/8100 [00:00<?, ?it/s]"). Do you think that I should oblige the user to use 2 or more than 2 n_jobs or try to fix this issue? => see "message_parallelization" and "if JOBS == 1:" in fit model and permutation importance (must be done for regression)
DONE-ok- Other classifiers: gaussian naive bayes (GNB), histogram-based gradient boosting (HGB), extra trees classifier (ET), adaboost (ADA), multi-layer perceptron (MLP), quadratic discriminant analysis (QDA), linear discriminant analysis (LDA)
DONE-ok- replace the message_permutation by "The permutation importance was successfully computed on both training and testing datasets"
DONE-ok- --nrepeats: help='Number of repetitions per feature for permutation importance; higher values provide more stable estimates but increase runtime. [OPTIONAL, DEFAULT: 10]' (must be done for regression)
DONE-ok- see NB and head(20) in log for combined_train_df, combined_test_df and combined_mutations_df
DONE-ok- expected obvervations for feature importance
-- For AdaBoost (ADA), feature importances are 0 or 1 because each weak learner (a decision stump) splits on only one feature, marking it as fully important while others remain unused.
-- For Histogram-based Gradient Boosting (HGB), all importances can be 0 when no meaningful split gains are computed—typically due to strong regularization, shallow trees, or limited feature variation.
DONE-ok- feature_importance_df and permutation_importance_df in modeling log with ajustment of # in modeling and prediction log (must be donne for regression)
DONE-ok- message controle permutation importance (PERMUTATIONIMPORTANCE) and number of repeatitions (NREPEATS): see message_compatibility_permutation_nrepeat (must be done for regression)
DONE-ok- remove Boruta (must be done for regression)
DONE-ok-adapt for classification, Pipeline and XGB (# detect classifier type even if wrapped in a Pipeline + # print a message about pipeline components + # perform prediction + # check compatibility between model and class encoder required for XGB model)
DONE-ok- fixe SKB + QDA defaut behavior without tuning: see QuadraticDiscriminantAnalysis(reg_param=0.05, tol=1e-4)
DONE-ok- make sure the message_selected_features in modeling and prediction is printed and in log (might be checked for regression)
DONE-ok- with rfSFM the differences between selectedd features ("The pipeline potentially selected and used") is do to random and manual rather than classifier (must be done with regression) => fixed with 
selector_model = RandomForestClassifier(
				random_state=42, # reproducibility
				n_jobs=1, # enforce single-thread determinism to ensure identical feature importances across runs and platforms
				bootstrap=False # # disable bootstrapping to reduce random variability in feature importance computation
			)
DONE-ok- absence of permutation bar for ET and RF => see "# fix nested parallelism issues for RandomForest and ExtraTrees so tqdm_joblib stays accurate" and "# compute permutation importance only if explicitly requested" (might be need for regression)
DONE-ok- issues prog bars of permutation importance for GB and RF regression
DONE-ok- digits management: '-di', '--digits' (must be done for regression)
DONE-ok- new blocks to fixed bugs related to encoding and alignment (might be done for regression)
DONE-# NEW perform splitting of the training and testing datasets according to the setting
DONE-# NEW enforce consistent one-hot encoded column order between train/test and across runs
DONE-# NEW determine expected feature order from the trained pipeline
DONE-# replace cat boost (CB) by catboost (CAT) in catboost (CAT) in regression
DONE-ok- safe guard "# ensure importances array is valid (numeric) even for models without native importances" into feature importance (might be done for regression)
DONE-ok check feature importance output of each regressors
DONE-ok- Feature importance (model specific and not systematic)
DONE-ok- slign modification for HGB, QDA and SVC in "# extract feature importance depending on classifier type" (might be also done for regression)
CLASSIFICATION
Model Type	Extraction Method	Notes
Tree-based (RF, ET, DT, XGB, ADA)	.feature_importances_	Standard impurity-based feature importance computed from average impurity reduction across all trees.
Histogram-based Gradient Boosting (HGB)	Aggregated split_gains_ over split_features_	Mean impurity reduction manually computed from internal tree split gains (_predictors), equivalent to scikit-learn’s internal computation for histogram-based models.
Linear Models (LR, LDA, Linear SVC without probability=True)	abs(coef_)	Magnitude of standardized coefficients; larger absolute values indicate stronger linear influence on the prediction.
Quadratic Discriminant Analysis (QDA)	Derived from between-class mean differences (means_)	Variance-normalized mean deviation per feature across classes; serves as a proxy for class-separating influence.
Support Vector Classification (SVC with probability=True or non-linear kernel)	NaN	No native feature importances are exposed when probability=True or when using non-linear kernels; use permutation or SHAP for interpretability.
Non-linear / Instance-based (KNN, MLP, GNB)	NaN	No native feature importances available; permutation or SHAP importance is recommended.
REGRESSION
RandomForestRegressor (RF)	final_estimator.feature_importances_	"tree-based impurity reduction (feature_importances_)"	Length = #selected/poly features; non-negative; sums ≈ 1 after normalization
DecisionTreeRegressor (DT)	final_estimator.feature_importances_	"tree-based impurity reduction (feature_importances_)"	Sparse importances (many zeros), matches splits
GradientBoostingRegressor (GB)	final_estimator.feature_importances_	"tree-based impurity reduction (feature_importances_)"	Smooth distribution; zero-only vector possible if small trees
AdaBoostRegressor (ADA)	final_estimator.feature_importances_	"tree-based impurity reduction (feature_importances_)"	Reflects weak learner contributions
ExtraTreesRegressor (if included)	feature_importances_	"tree-based impurity reduction (feature_importances_)"	More unstable than RF; check length and non-negativity
XGBRegressor (XGB)	booster.get_score(importance_type=xgb_importance_type)	"xgboost's {importance_type}-based importance" (usually "gain", "weight", "cover")	Importance vector length = booster.feature_names; distribution depends on importance_type
LGBMRegressor (LGBM)	final_estimator.booster_.feature_importance(importance_type=lgbm_importance_type)	"lightgbm's {importance_type}-based importance" (usually "gain" or "split")	Length = raw booster features; often aligned with OHE columns
HistGradientBoostingRegressor (HGB)	get_feature_importances() or fallback aggregation of _predictors → split_features_ / split_gains_	"histogram-based mean impurity reduction (auto fallback to internal split gains)"	Expected behavior: all-zero importances when no informative splits exist
CatBoostRegressor (CAT)	final_estimator.get_feature_importance(type="PredictionValuesChange")	"catboost's loss-based importance"	Should return non-negative importances; check alignment with encoded features
BayesianRidge (BRI)	abs(final_estimator.coef_)	"absolute coefficient magnitude (coef_)"	One importance per feature; magnitude-based interpretation
Ridge (RI)	abs(coef_)	"absolute coefficient magnitude (coef_)"	All features non-zero; shrinkage affects magnitudes
Lasso (LA)	abs(coef_)	"absolute coefficient magnitude (coef_)"	Many zeros expected (L1-sparse model)
ElasticNet (EN)	abs(coef_)	"absolute coefficient magnitude (coef_)"	Intermediate between Lasso and Ridge
LinearRegression (PN)	abs(coef_)	"absolute coefficient magnitude (coef_)"	Must match polynomial expansion dimension if poly used
HuberRegressor (HU)	abs(coef_)	"absolute coefficient magnitude (coef_)"	Similar to linear regression but more robust
PolynomialFeatures (when present)	Names via poly.get_feature_names_out() before selection mask	N/A	Ensure the number of generated features matches polynomial degree and input size
MLPRegressor (MLP)	NaN placeholder vector	"NaN placeholder"	Always NaN — MLP has no native importance
KNeighborsRegressor (KNN)	NaN placeholder vector	"NaN placeholder"	Always NaN — distance-based model
SVR (SVR)	NaN placeholder vector	"NaN placeholder"	Non-linear kernel → no coefficients available
NuSVR (NSV)	NaN placeholder vector	"NaN placeholder"	Same as SVR
DONE-ok- SafeCatBoostClassifier(CatBoostClassifier) might be necessary for regression
DONE-ok- implement AdaBoostRegressor (ADA) and ExtraTreesRegressor (ET) in the regression workflow




TO DO FOR CLASSIFICATION
- For LGBM and HGB implementation, check if it is neccessary to adapte "# ensure numeric compatibility" and "# combine expectation and prediction" (training and testing)
-ok-latter Sampling methods
-ok- Potential SHAP (computationally intensive)
-ok- use the count_selected_features function of GenomicDataBasedRegreesion v1.2.0 into classification because it is stylistically aligned function compatible with both workflows
-ok replace by message_number_phenotype_classes = ("The presence of phenotype in the input file of phenotypes was improperly controlled (i.e., the second column is missing)")
-ok- faster than pandas read => let's keep pandas from now for simplicity		
-ok- keep random_state=42 in every call to permutation_importance to improves debugging and reliability without bias permutation importance (ok for regression, must be done for classification)
-ok- harmonization of classifiers and regressors
-ok- make sure comments "# control >= 1" for restricted_int_digits and restricted_debug_level
-ok- update "# round digits of a dataframe avoid SettingWithCopyWarning with .copy()" blocks (modeling and prediction) to deal with float rather than float32
-ok- check "# normalize only here (since dataset column exists)" for classification if it is necessary to replace:
# df_all["dataset"] = df_all["dataset"].astype(str).str.strip().str.lower()
# by df_all["dataset"] = df_all["dataset"].astype(str).str.strip().str.lower()
-ok- remove "classifier" in help "decision tree classifier (DT), extra trees classifier (ET)" and in "## initialize the classifier"
-ok- harmonize "random_state=42" in "## initialize the classifier"
-ok- # enforce single-thread determinism with n_jobs=1 for RF and ET
-ok- remove " -de 20" and " -w" from examples







I am building a workflow called GenomicBasedRegression with two subcommands: first to build a model (modeling subcommand) and second to perform prediction based on a prebuilt model (prediction). More precisely, this workflow transform binary and/or categorical mutations (features) into binary encoded mutations (encoded features) with OneHotEncoder(), then perform a potential feature selection (SelectKBest (SKB), SelectFromModel with Lasso (laSFM), SelectFromModel with ElasticNet (enSFM), SelectFromModel with Random Forest (rfSFM), or Boruta (BO)) and regressor-based model fitting (bayesian bidge (BRI), cat boost (CB), decision tree (DT), elasticnet (EN), gradient boosting (GB), hist gradient boosting (HGB), huber (HU), k-nearest neighbors (KNN), lassa (LA), light gradient goosting machine (LGBM), multi-layer perceptron (MLP), nu support vector (NSV), polynomial (PN), ridge (RI), random forest (RF), support vector regressor (SVR) or extreme gradient boosting (XGB)) through the Pipeline() function with the objective to predict continuous phenotype (target). After prediction, I use a custom ResidualQuantileWrapper to calculate prediction intervals (PIs) of samples from the training and testing datesets build during the modeling subcommand, as well as another testing dataset during the prediction subcommand. 

Could you let me know what should I modify in my workflow below to remove completelly Boruta because it is too slow and I did not succeed to make working the progress bar with Boruta?






























bayesian bidge (BRI): BayesianRidge()
cat boost (CB): cb.CatBoostRegressor()
decision tree (DT): DecisionTreeRegressor()
elasticnet (EN): ElasticNet()
gradient boosting (GB): GradientBoostingRegressor()
hist gradient boosting (HGB): HistGradientBoostingRegressor()
huber (HU): HuberRegressor()
k-nearest neighbors (KNN): KNeighborsRegressor()
lassa (LA): Lasso()
light gradient goosting machine (LGBM): lgbm.LGBMRegressor()
multi-layer perceptron (MLP): MLPRegressor()
nu support vector (NSV): NuSVR()
polynomial (PN): PolynomialFeatures() + StandardScaler() + LinearRegression()
ridge (RI): Ridge()
random forest (RF): RandomForestRegressor()
support vector regressor (SVR): SVR()
extreme gradient boosting (XGB): xgb.XGBRegressor(objective='reg:squarederror')









I am building a workflow with two subcommands: first to build a model (modeling subcommand) and second to perform prediction based on a prebuilt model (prediction). More precisely, this workflow transform binary and/or categorical mutations (features) into binary encoded mutations (encoded features) with OneHotEncoder(), then perform a potential feature selection (SelectKBest (SKB), SelectFromModel with Lasso (laSFM), SelectFromModel with ElasticNet (enSFM), SelectFromModel with Random Forest (rfSFM), or Boruta (BO)) and regressor-based model fitting (bayesian bidge (BRI), cat boost (CB), decision tree (DT), elasticnet (EN), gradient boosting (GB), hist gradient boosting (HGB), huber (HU), k-nearest neighbors (KNN), lassa (LA), light gradient goosting machine (LGBM), multi-layer perceptron (MLP), nu support vector (NSV), polynomial (PN), ridge (RI), random forest (RF), support vector regressor (SVR) or extreme gradient boosting (XGB)) through the Pipeline() function with the objective to predict continuous phenotype (target). After prediction, I use a custom ResidualQuantileWrapper to calculate prediction intervals (PIs) of samples from the training and testing datesets build during the modeling subcommand, as well as another testing dataset during the prediction subcommand. 

Yesturday, you help me to implement a block below aiming at building a dataframe with encoded feature used by the model together with corresponding importance values and you recommand me to add set_config(transform_output="pandas") before def main().

		# output a dataframe of features used by the final model with ranked importance scores
		# get the final estimator from the pipeline or directly if standalone
		final_estimator = best_model[-1] if hasattr(best_model, '__getitem__') else best_model
		# initialize list of feature names and selection mask
		feature_encoded_lst = None
		support_mask = None
		selector = None
		try:
			# check if the model is a pipeline
			if hasattr(best_model, 'named_steps'):
				# if it contains a polynomial transformer, extract feature names
				if 'poly' in best_model.named_steps and hasattr(best_model.named_steps['poly'], 'get_feature_names_out'):
					input_features = X_train_encoded.columns
					feature_encoded_lst = best_model.named_steps['poly'].get_feature_names_out(input_features=input_features)
				else:
					# otherwise use column names from the encoded training data
					feature_encoded_lst = X_train_encoded.columns
				# check for a feature selection step
				if 'feature_selection' in best_model.named_steps:
					selector = best_model.named_steps['feature_selection']
					# if get_support is defined, use it to filter selected features
					if hasattr(selector, 'get_support'):
						support_mask = selector.get_support()
						feature_encoded_lst = np.array(feature_encoded_lst)[support_mask]
					# otherwise check for ranking_ attribute, used by boruta
					elif hasattr(selector, 'ranking_'):
						ranking = np.array(selector.ranking_)
						support_mask = ranking == 1
						feature_encoded_lst = np.array(feature_encoded_lst)[support_mask]
					else:
						# fallback: assume all features were kept
						support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			elif hasattr(best_model, 'get_feature_names_out'):
				feature_encoded_lst = best_model.get_feature_names_out()
				support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			else:
				feature_encoded_lst = X_train_encoded.columns
				support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			message_importance_encoded_feature_names = "The full encoded feature names were recovered from the pipeline"
		except Exception:
			feature_encoded_lst = X_train_encoded.columns
			support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			message_importance_encoded_feature_names = "The full encoded feature names were not recovered from the pipeline"
		print(message_importance_encoded_feature_names)
		# ensure feature names are a list
		if hasattr(feature_encoded_lst, 'tolist'):
			feature_encoded_lst = feature_encoded_lst.tolist()
		# get importances depending on the model type
		if isinstance(final_estimator, cb.CatBoostRegressor):
			importances = final_estimator.get_feature_importance(prettified=False)
		elif hasattr(final_estimator, 'feature_importances_'):
			importances = final_estimator.feature_importances_
		elif hasattr(final_estimator, 'coef_'):
			importances = np.abs(final_estimator.coef_.ravel() if hasattr(final_estimator.coef_, 'ravel') else final_estimator.coef_)
		else:
			importances = np.array([np.nan] * len(feature_encoded_lst))
		# check for size mismatch between importances and feature names
		if len(importances) != len(feature_encoded_lst):
			min_len = min(len(importances), len(feature_encoded_lst))
			importances = importances[:min_len]
			feature_encoded_lst = feature_encoded_lst[:min_len]
		# print a message
		message_importance_count = (
			"The best model returned "
			+ str(len(importances))
			+ " importance values for "
			+ str(len(feature_encoded_lst))
			+ " encoded features"
		)
		print(message_importance_count)
		# create dataframe of feature importances and sort by descending importance
		feature_importance_df = pd.DataFrame({"feature": feature_encoded_lst, "importance": importances})
		feature_importance_df = feature_importance_df.sort_values(by="importance", ascending=False).reset_index(drop=True)
		print(feature_importance_df)

Today I tested the 17 implemented regressors below, without or with set_config(transform_output="pandas"), and I oberved that HGB, KNN, MLP and NSV provided NaN rather than importance values.

Final regressor	without set_config(transform_output="pandas")	with set_config(transform_output="pandas")
bayesian bidge (BRI): BayesianRidge()	importance values	importance values
cat boost (CB): cb.CatBoostRegressor()	importance values	importance values
decision tree (DT): DecisionTreeRegressor()	importance values	importance values
elasticnet (EN): ElasticNet()	importance values	importance values
gradient boosting (GB): GradientBoostingRegressor()	importance values	importance values
hist gradient boosting (HGB): HistGradientBoostingRegressor()	NaN	NaN
huber (HU): HuberRegressor()	importance values	importance values
k-nearest neighbors (KNN): KNeighborsRegressor()	NaN	NaN
lassa (LA): Lasso()	importance values	importance values
light gradient goosting machine (LGBM): lgbm.LGBMRegressor()	importance values	importance values + error
multi-layer perceptron (MLP): MLPRegressor()	NaN	NaN
nu support vector (NSV): NuSVR()	NaN	NaN
polynomial (PN): PolynomialFeatures() + StandardScaler() + LinearRegression()	importance values	importance values
ridge (RI): Ridge()	importance values	importance values
random forest (RF): RandomForestRegressor()	importance values	importance values
support vector regressor (SVR): SVR()	NaN	NaN
extreme gradient boosting (XGB): xgb.XGBRegressor(objective='reg:squarederror')	importance values	importance values

In addition, I observed that LGBM made the error below when using set_config(transform_output="pandas").

Traceback (most recent call last):   File "/home/IZSNT/n.radomski/Downloads/GenomicBasedRegression/GenomicBasedRegression.py", line 2048, in <module>     main()   File "/home/IZSNT/n.radomski/Downloads/GenomicBasedRegression/GenomicBasedRegression.py", line 1594, in main     res_wrapper.fit(X_train_encoded, y_train)   File "/home/IZSNT/n.radomski/Downloads/GenomicBasedRegression/GenomicBasedRegression.py", line 338, in fit     self.estimator.fit(X, y)   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/sklearn/base.py", line 1473, in wrapper     return fit_method(estimator, *args, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/sklearn/pipeline.py", line 473, in fit     self._final_estimator.fit(Xt, y, **last_step_params["fit"])   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/sklearn.py", line 1398, in fit     super().fit(   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/sklearn.py", line 1049, in fit     self._Booster = train(                     ^^^^^^   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/engine.py", line 297, in train     booster = Booster(params=params, train_set=train_set)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/basic.py", line 3656, in __init__     train_set.construct()   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/basic.py", line 2590, in construct     self._lazy_init(   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/basic.py", line 2209, in _lazy_init     self.set_label(label)   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/basic.py", line 3077, in set_label     label_array = _list_to_1d_numpy(label, dtype=np.float32, name="label")                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/basic.py", line 380, in _list_to_1d_numpy     _check_for_bad_pandas_dtypes(data.to_frame().dtypes)   File "/home/IZSNT/n.radomski/.local/lib/python3.12/site-packages/lightgbm/basic.py", line 805, in _check_for_bad_pandas_dtypes     raise ValueError( ValueError: pandas dtypes must be int, float or bool. Fields with bad pandas dtypes: phenotype: object

Whould you really recommand to use set_config(transform_output="pandas")?

-------------------------------------

Concerning the models without importances, KNeighborsRegressor (REGRESSOR == 'KNN'), MLPRegressor (REGRESSOR == 'MLP'), NuSVR (REGRESSOR == 'NSV'), SVR (REGRESSOR == 'SVR') and HistGradientBoostingRegressor (REGRESSOR == 'HGB'), could you help me to modify the block below (keeping comments, avoiding maj in comments, avoiding empty lines) with the objective to replace message_importance_count by "The selected model regressor did not expose feature importance natively" if these models where selected by the user (REGRESSOR is an input argument from the user)?

		# output a dataframe of features used by the final model with ranked importance scores
		# get the final estimator from the pipeline or directly if standalone
		final_estimator = best_model[-1] if hasattr(best_model, '__getitem__') else best_model
		# initialize list of feature names and selection mask
		feature_encoded_lst = None
		support_mask = None
		selector = None
		try:
			# check if the model is a pipeline
			if hasattr(best_model, 'named_steps'):
				# if it contains a polynomial transformer, extract feature names
				if 'poly' in best_model.named_steps and hasattr(best_model.named_steps['poly'], 'get_feature_names_out'):
					input_features = X_train_encoded.columns
					feature_encoded_lst = best_model.named_steps['poly'].get_feature_names_out(input_features=input_features)
				else:
					# otherwise use column names from the encoded training data
					feature_encoded_lst = X_train_encoded.columns
				# check for a feature selection step
				if 'feature_selection' in best_model.named_steps:
					selector = best_model.named_steps['feature_selection']
					# if get_support is defined, use it to filter selected features
					if hasattr(selector, 'get_support'):
						support_mask = selector.get_support()
						feature_encoded_lst = np.array(feature_encoded_lst)[support_mask]
					# otherwise check for ranking_ attribute, used by boruta
					elif hasattr(selector, 'ranking_'):
						ranking = np.array(selector.ranking_)
						support_mask = ranking == 1
						feature_encoded_lst = np.array(feature_encoded_lst)[support_mask]
					else:
						# fallback: assume all features were kept
						support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			elif hasattr(best_model, 'get_feature_names_out'):
				feature_encoded_lst = best_model.get_feature_names_out()
				support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			else:
				feature_encoded_lst = X_train_encoded.columns
				support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			message_importance_encoded_feature_names = "The full encoded feature names were recovered from the pipeline"
		except Exception:
			feature_encoded_lst = X_train_encoded.columns
			support_mask = np.ones(len(feature_encoded_lst), dtype=bool)
			message_importance_encoded_feature_names = "The full encoded feature names were not recovered from the pipeline"
		print(message_importance_encoded_feature_names)
		# ensure feature names are a list
		if hasattr(feature_encoded_lst, 'tolist'):
			feature_encoded_lst = feature_encoded_lst.tolist()
		# get importances depending on the model type
		if isinstance(final_estimator, cb.CatBoostRegressor):
			importances = final_estimator.get_feature_importance(prettified=False)
		elif hasattr(final_estimator, 'feature_importances_'):
			importances = final_estimator.feature_importances_
		elif hasattr(final_estimator, 'coef_'):
			importances = np.abs(final_estimator.coef_.ravel() if hasattr(final_estimator.coef_, 'ravel') else final_estimator.coef_)
		else:
			importances = np.array([np.nan] * len(feature_encoded_lst))
		# check for size mismatch between importances and feature names
		if len(importances) != len(feature_encoded_lst):
			min_len = min(len(importances), len(feature_encoded_lst))
			importances = importances[:min_len]
			feature_encoded_lst = feature_encoded_lst[:min_len]
		# print a message
		message_importance_count = (
			"The best model returned "
			+ str(len(importances))
			+ " importance values for "
			+ str(len(feature_encoded_lst))
			+ " encoded features"
		)
		print(message_importance_count)
		# create dataframe of feature importances and sort by descending importance
		feature_importance_df = pd.DataFrame({"feature": feature_encoded_lst, "importance": importances})
		feature_importance_df = feature_importance_df.sort_values(by="importance", ascending=False).reset_index(drop=True)
		print(feature_importance_df)

-------------------------------------------

# TO CHECK
Don’t support feature importance natively. To address this:
You can fill importances with NaN as you do now, or:
Use permutation importance as a fallback:
Use this only if you really need an importance estimate, but be aware it’s slow and sensitive to noise.
from sklearn.inspection import permutation_importance
result = permutation_importance(best_model, X_train_encoded, y_train, n_repeats=10, random_state=42)
importances = result.importances_mean

# TO CHECK
retrieve the kind of importance values (coef, rank ....)

¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯

If I understood well the importance values might be different elements depending of the used model regressor, such like coeficient or something else?














Could you remember me why it was juducious to implement SelectFromModel with Lasso (laSFM), SelectFromModel with ElasticNet (enSFM), SelectFromModel with Random Forest (rfSFM)?

Method	Handles Collinearity	Sparse Selection	Captures Non-Linearity	Robust to Outliers
laSFM	❌ No	✅ Yes	❌ No	❌ No
enSFM	✅ Yes	✅ Moderate	❌ No	❌ No
rfSFM	✅ Yes	❌ No (but filters)	✅ Yes	✅ Yes

When using the polynomial (PN) model regressor, I obsevred inflated predictions and inflated prediction intervals, especially with my prediction subcommand (perform prediction based on a prebuilt model), if I do not use feature selections or if I use features selections SKB or enSFM, while I do not observe these inflated predictions and inflated prediction intervals if I use laSFM or rfSFM. Futhermore, I did not observed inflated predictions and inflated prediction intervals when I used SKB feture selection with all the other implemented model regressor (bayesian bidge (BRI), cat boost (CB), decision tree (DT), elasticnet (EN), gradient boosting (GB), hist gradient boosting (HGB), huber (HU), k-nearest neighbors (KNN), lassa (LA), light gradient goosting machine (LGBM), multi-layer perceptron (MLP), nu support vector (NSV), polynomial (PN), ridge (RI), random forest (RF), support vector regressor (SVR) or extreme gradient boosting (XGB)) Do you know why this behavior seems to be specific to the polynomial (PN) model regressor?

# the polynomial model is prone to instability, overfitting, and exploding outputs for high-dimensional, sparse, or unfiltered data because it expands the input feature space into polynomial combinations

Feature Selector	Good for PN?	Why
SKB	❌ Risky	Keeps weak/uncorrelated features, not interaction-aware
enSFM	⚠️ Risky	May keep correlated noise, less sparse than Lasso
laSFM	✅ Good	Produces sparse, strong feature set
rfSFM	✅ Good	Nonlinear feature importance helps capture useful predictors

If continuing with PN:
Always use aggressive feature selection (laSFM or rfSFM) before polynomial expansion.
Consider lowering polynomial degree (e.g., from 3 → 2).
Add a Ridge or Lasso regressor after the polynomial transformer to control coefficient magnitude.
Use interaction_only=True in PolynomialFeatures() if full expansion is not necessary.
Consider standardization (StandardScaler) before fitting.

Optional: Use a pipeline like this for PN:
Pipeline([
    ('feature_selection', SelectFromModel(Lasso(...))),
    ('poly', PolynomialFeatures(degree=2, include_bias=False)),
    ('scaler', StandardScaler()),  # optional, but helps
    ('regressor', Ridge(alpha=1.0))  # better than plain LinearRegression
])

Infact, StandardScaler() is currently not used in my workflow because the one-hot encoding provide only binary features and we decided to not use StandardScaler() which would lead to minimize the scale and minize performance for the other implemented model regressor (bayesian bidge (BRI), cat boost (CB), decision tree (DT), elasticnet (EN), gradient boosting (GB), hist gradient boosting (HGB), huber (HU), k-nearest neighbors (KNN), lassa (LA), light gradient goosting machine (LGBM), multi-layer perceptron (MLP), nu support vector (NSV), ridge (RI), random forest (RF), support vector regressor (SVR) or extreme gradient boosting (XGB)).

Nevertheless, adding StandardScaler() between PolynomialFeatures() and plain LinearRegression() might improve the model regressor polynomial (PN).

Futhermore, I prefer to keep plain LinearRegression() for the model regressor polynomial (PN) because I want to stick to the definition of polynomial regression (i.e., PolynomialFeatures() + LinearRegression()).

Concerning the modification of the the model regressor polynomial (PN), would recommand to 1/ keep the current workflow below, 2/ add StandardScaler() between PolynomialFeatures() and plain LinearRegression(), or 3/ remove completely the the model regressor polynomial (PN) from the workflow?

		# prepare elements of the model
		## initialize the feature selection method (without tuning parameters: deterministic and repeatable)
		if FEATURESELECTION == 'None':
			message_feature_selection = "The provided feature selection method was properly recognized: None"
			print(message_feature_selection)
			selected_feature_selector = None
		elif FEATURESELECTION == 'SKB':
			message_feature_selection = "The provided feature selection method was properly recognized: SelectKBest (SKB)"
			print(message_feature_selection)
			selected_feature_selector = SelectKBest(
				score_func=ft.partial( # partial allow reproducibility
					mutual_info_regression, # mutual_info_regression captures linear and non-linear dependancies, default f_regression was not proposed per default because it captures only linear dependancies, optional chi2 is not recommended for regression, all score_func can be used through tunining parameters
					random_state=42 # reproducibility
				), 
				k=10 # default top k features can be modified in the parameters file if needed
			) 
		elif FEATURESELECTION in ['laSFM', 'rfSFM', 'enSFM']:
			if FEATURESELECTION == 'laSFM':
				message_feature_selection = "The provided feature selection method was properly recognized: SelectFromModel with lasso (laSFM)"
				selector_model = Lasso(random_state=42) # reproducibility
			elif FEATURESELECTION == 'rfSFM':
				message_feature_selection = "The provided feature selection method was properly recognized: SelectFromModel with random forest (rfSFM)"
				selector_model = RandomForestRegressor(random_state=42) # reproducibility
			elif FEATURESELECTION == 'enSFM':
				message_feature_selection = "The provided feature selection method was properly recognized: SelectFromModel with elasticnet (enSFM)"
				selector_model = ElasticNet(random_state=42) # reproducibility
			print(message_feature_selection)
			selected_feature_selector = SelectFromModel(
				estimator=selector_model,
				threshold=None # default threshold behavior based on model, user can specify max_features in the parameters file if needed together with 'threshold': [-float('inf')] to rank features by importance
			)
		elif FEATURESELECTION == 'BO':
			message_feature_selection = "The provided feature selection method was properly recognized: Boruta (BO)"
			print(message_feature_selection)
			# Boruta requires a regressor internally, for instance RandomForestRegressor with fast default or param overrides
			boruta_estimator = RandomForestRegressor(random_state=42) # reproducibility
			# create Boruta selector with fast default custom parameters, can be expanded later from parameters file
			boruta_selector = BorutaSelectorDF(
				estimator=boruta_estimator,
				n_estimators='auto', # use the same number of estimators as defined in the estimator (custom for speed, Boruta default: 100)
				max_iter=10, # few iterations to reduce runtime (custom for speed, Boruta default: 100)
				perc=85, # stricter cutoff can reduce number of features selected (custom for speed, Boruta default: 100)
				two_step=True, # can reduce the number of iterations (custom for speed, Boruta default: False)
				verbose=0, # avoid print in shell (custom, Boruta default: 1)
				random_state=42 # reproducibility
			)
			selected_feature_selector = boruta_selector
		else:
			message_feature_selection = "The provided feature selection method is not implemented yet"
			raise Exception(message_feature_selection)

		## initialize the regressor (without tuning parameters: deterministic and repeatable if possible)
		if REGRESSOR == 'BRI':
			message_regressor = "The provided regressor was properly recognized: bayesian ridge (BRI)"
			print(message_regressor)
			selected_regressor = BayesianRidge()
		elif REGRESSOR == 'CB':
			message_regressor = "The provided regressor was properly recognized: catboost (CB)"
			print(message_regressor)
			selected_regressor = cb.CatBoostRegressor(random_state=42, verbose=0)
		elif REGRESSOR == 'DT':
			message_regressor = "The provided regressor was properly recognized: decision tree (DT)"
			print(message_regressor)
			selected_regressor = DecisionTreeRegressor(random_state=42)
		elif REGRESSOR == 'EN':
			message_regressor = "The provided regressor was properly recognized: elasticNet (EN)"
			print(message_regressor)
			selected_regressor = ElasticNet(random_state=42, selection='random')
		elif REGRESSOR == 'GB':
			message_regressor = "The provided regressor was properly recognized: gradient boosting (GB)"
			print(message_regressor)
			selected_regressor = GradientBoostingRegressor(random_state=42)
		elif REGRESSOR == 'HGB':
			message_regressor = "The provided regressor was properly recognized: hist gradient boosting (HGB)"
			print(message_regressor)
			selected_regressor = HistGradientBoostingRegressor(random_state=42)
		elif REGRESSOR == 'HU':
			message_regressor = "The provided regressor was properly recognized: huber (HU)"
			print(message_regressor)
			selected_regressor = HuberRegressor()
		elif REGRESSOR == 'KNN':
			message_regressor = "The provided regressor was properly recognized: k-nearest neighbors (KNN)"
			print(message_regressor)
			selected_regressor = KNeighborsRegressor()
		elif REGRESSOR == 'LA':
			message_regressor = "The provided regressor was properly recognized: lasso (LA)"
			print(message_regressor)
			selected_regressor = Lasso(random_state=42)
		elif REGRESSOR == 'LGBM':
			message_regressor = "The provided regressor was properly recognized: Light Gradient Boosting Machine (LGBM)"
			print(message_regressor)
			selected_regressor = lgbm.LGBMRegressor(random_state=42, verbose=-1)
		elif REGRESSOR == 'MLP':
			message_regressor = "The provided regressor was properly recognized: multi-layer perceptron (MLP)"
			print(message_regressor)
			selected_regressor = MLPRegressor(random_state=42)
		elif REGRESSOR == 'NSV':
			message_regressor = "The provided regressor was properly recognized: nu support vector (NSV)"
			print(message_regressor)
			selected_regressor = NuSVR()
		elif REGRESSOR == 'PN':
			message_regressor = "The provided regressor was properly recognized: polynomial (PN)"
			print(message_regressor)
			selected_regressor = LinearRegression()
		elif REGRESSOR == 'RF':
			message_regressor = "The provided regressor was properly recognized: random forest (RF)"
			print(message_regressor)
			selected_regressor = RandomForestRegressor(random_state=42)
		elif REGRESSOR == 'RI':
			message_regressor = "The provided regressor was properly recognized: ridge (RI)"
			print(message_regressor)
			selected_regressor = Ridge()
		elif REGRESSOR == 'SVR':
			message_regressor = "The provided regressor was properly recognized: support vector regression (SVR)"
			print(message_regressor)
			selected_regressor = SVR()
		elif REGRESSOR == 'XGB':
			message_regressor = "The provided regressor was properly recognized: extreme gradient boosting (XGB)"
			print(message_regressor)
			selected_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
		else: 
			message_regressor = "The provided regressor is not implemented yet"
			raise Exception(message_regressor)

		## build the pipeline
		### create an empty list
		steps = []
		### add feature selection step if specified
		if FEATURESELECTION in ['SKB', 'laSFM', 'rfSFM', 'enSFM', 'BO']:
			steps.append(('feature_selection', selected_feature_selector))
		### add polynomial features if the regressor is polynomial
		if REGRESSOR == 'PN':
			steps.append(('poly', PolynomialFeatures(degree=1, include_bias=False)))  # default linear regression (degree=1) can be changed using the 'degree' tuning parameter
		### add the final model
		steps.append(('model', selected_regressor))
		### create the pipeline
		selected_pipeline = Pipeline(steps)
		### print a message
		message_pipeline = "The pipeline components were properly recognized: " + re.sub(r'\s+', ' ', str(selected_pipeline)).strip()
		print(message_pipeline)

Benefits of Option 2 (Add StandardScaler() for PN only)
Keeps your pipeline consistent for other regressors (no StandardScaler()).
Improves numerical stability of LinearRegression() on expanded polynomial features.
Doesn’t modify your canonical definition of polynomial regression—it just preprocesses the expanded feature space, not the binary input space.
Requires minimal change in your current code.

--------------------------------------------

Let's talk about another suject. Independantly of the combinaison of the potential feature selection method (SelectKBest (SKB), SelectFromModel with Lasso (laSFM), SelectFromModel with ElasticNet (enSFM), SelectFromModel with Random Forest (rfSFM), or Boruta (BO)) and model regressor (bayesian bidge (BRI), cat boost (CB), decision tree (DT), elasticnet (EN), gradient boosting (GB), hist gradient boosting (HGB), huber (HU), k-nearest neighbors (KNN), lassa (LA), light gradient goosting machine (LGBM), multi-layer perceptron (MLP), nu support vector (NSV), polynomial (PN), ridge (RI), random forest (RF), support vector regressor (SVR) or extreme gradient boosting (XGB)) used by the user, I would like to output during my modeling subcommand a dataframe of features used by the model regressor, together with ranked feature importance metric. Could you help me to spote where could I add this in my script below?

		## initialize the parameters
		### if the tuning parameters are not provided by the user
		if PARAMETERS == None:
			parameters = [{}]
			message_parameters = "The tuning parameters were not provided by the user"
			print(message_parameters)
		### if the tuning parameters are provided by the user
		elif PARAMETERS != None:
			### read provided tuning parameters and convert string dictionary to Python dictionary keeping the convenience of writing real Python objects into the parameter file (e.g., chi2, -float('inf'), ....)
			with open(PARAMETERS, "r") as parameters_file:
				parameters = [eval(parameters_file.read())]
			### print a message
			message_parameters = "The provided tuning parameters were properly recognized: " + str(parameters)
			print(message_parameters)

		# build the model
		## prepare the grid search cross-validation (CV) first
		model = GridSearchCV(
			estimator=selected_pipeline,
			param_grid=parameters,
			cv=FOLD,
			scoring='neg_root_mean_squared_error', # average prediction error in the same unit as your target # the one with the lowest RMSE (i.e., highest neg-RMSE) was chosen)
			n_jobs=JOBS,
			verbose=0 # do not display any messages or logs
		)

		## compute metrics related to grid search CV
		### number of distinct parameter names (i.e., how many parameters are tuned)
		n_param_names = len({k for d in parameters for k in d})
		### number of parameter value options (i.e., how many values are tried in total)
		n_total_values = sum(len(v) for d in parameters for v in d.values())
		### number of parameter combinations (i.e., Cartesian product of all value options)
		param_combinations = len(list(ParameterGrid(parameters)))
		### number of fits during cross-validation (i.e., combinations × folds)
		gridsearchcv_fits = param_combinations * FOLD
		### print a message
		message_metrics_cv = "The cross-validation setting implied: " + str(n_param_names) + " distinct parameter names, " + str(n_total_values) + " parameter value options, " + str(param_combinations) + " parameter combinations, and " + str(gridsearchcv_fits) + " fits during cross-validation"
		print(message_metrics_cv)

		## fit the model
		### use tqdm.auto rather than tqdm library because it automatically choose the best display format (terminal, notebook, etc.)
		### use a tqdm progress bar from the tqdm_joblib library (compatible with GridSearchCV)
		### use a tqdm progress bar immediately after the last print (position=0), disable the additional bar after completion (leave=False), and allow for dynamic resizing (dynamic_ncols=True)
		### force GridSearchCV to use the threading backend to avoid the DeprecationWarning from fork and ChildProcessError from the loky backend (default in joblib)
		### threading is slower than loky, but it allows using a progress bar with GridSearchCV and avoids the DeprecationWarning and ChildProcessError
		with tqa.tqdm(total=gridsearchcv_fits, desc="Model building progress", position=0, leave=False, dynamic_ncols=True) as progress_bar:
			with jl.parallel_backend('threading', n_jobs=JOBS):
				with tqjl.tqdm_joblib(progress_bar):
					model.fit(
						X_train_encoded.astype(np.float32), # ensure numeric compatibility (astype(np.float32)) with upstream encoding (sparse_output=False) and efficiency float32 dtype) especially tree-based regressors (e.g., HistGradientBoostingRegressor, XGBRegressor, LightGBM)
						y_train.values.astype(np.float32).ravel() # flatten the array into a 1D shape expected by most regressors (ravel)
					)

		## print best parameters
		if PARAMETERS == None:
			message_best_parameters = "The best parameters during model cross-validation were not computed because they were not provided"
		elif PARAMETERS != None:
			message_best_parameters = "The best parameters during model cross-validation were: " + str(model.best_params_)
		print(message_best_parameters)
		## print best score
		message_best_score = "The best negative root mean squared error during model cross-validation was: " + str(round(model.best_score_, digits))
		print(message_best_score)

		# retrieve the combinations of tested parameters and corresponding scores
		## combinations of tested parameters
		allparameters_lst = model.cv_results_['params']
		## corresponding scores
		allscores_nda = model.cv_results_['mean_test_score']
		## transform the list of parameters into a dataframe
		allparameters_df = pd.DataFrame({'parameters': allparameters_lst})
		## transform the ndarray of scores into a dataframe
		allscores_df = pd.DataFrame({'scores': allscores_nda})
		## concatenate horizontally dataframes
		all_scores_parameters_df = pd.concat(
			[allscores_df, 
			allparameters_df], 
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
		## remove unnecessary characters
		### replace each dictionary by string
		all_scores_parameters_df['parameters'] = all_scores_parameters_df['parameters'].apply(lambda x: str(x))
		### replace special characters { and } by nothing
		all_scores_parameters_df['parameters'] = all_scores_parameters_df['parameters'].replace(r'[\{\}]', '', regex=True)

		# select the best model
		best_model = model.best_estimator_
		
		# count features
		## count the number of features selected by feature selection actually used by the final regressor
		selected_features_int = count_selected_features(best_model, X_train_encoded)
		## print a message
		message_selected_features = (
			"The pipeline potentially selected and used "
			+ str(selected_features_int)
			+ " encoded features to train the model"
		)
		print(message_selected_features)

		# perform prediction
		## from the training dataset
		y_pred_train = best_model.predict(X_train_encoded)
		## from the testing dataset
		y_pred_test = best_model.predict(X_test_encoded)

		# evaluate model
		# root mean squared error (RMSE): square root of the mean of the squared differences between true and predicted values
		# → sensitive to large errors; useful when large deviations are particularly undesirable
		# mean squared error (MSE): average of the squared differences between true and predicted values
		# → penalizes larger errors more heavily; often used for optimization during model training
		# symmetric mean absolute percentage error (SMAPE): mean of the absolute differences between true and predicted values, divided by their average magnitude
		# → scale-independent and symmetric; useful when comparing performance across datasets with different scales
		# mean absolute percentage error (MAPE): mean of the absolute percentage errors between true and predicted values
		# → interpretable as average percentage error; can be misleading with near-zero targets
		# mean absolute error (MAE): average of the absolute differences between true and predicted values
		# → more robust to outliers than MSE; intuitive and scale-dependent
		# R-squared (R2): proportion of the variance in the dependent variable that is predictable from the independent variables
		# → indicates goodness of fit; higher is better, but does not penalize for model complexity
		# adjusted R-squared (aR2): R-squared adjusted for the number of predictors; it accounts for model complexity
		# → preferred when comparing models with different numbers of predictors

		## compute metrics
		### RMSE
		rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
		rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
		### MSE
		mse_train = mean_squared_error(y_train, y_pred_train)
		mse_test = mean_squared_error(y_test, y_pred_test)
		### SMAPE
		smape_train = smape(y_train, y_pred_train, threshold=1e-3)
		smape_test = smape(y_test, y_pred_test, threshold=1e-3)
		### MAPE
		mape_train = mape(y_train, y_pred_train, threshold=1e-3)
		mape_test = mape(y_test, y_pred_test, threshold=1e-3)
		### MAE
		mae_train = mean_absolute_error(y_train, y_pred_train)
		mae_test = mean_absolute_error(y_test, y_pred_test)	
		### R2
		r2_train = r2_score(y_train, y_pred_train)
		r2_test = r2_score(y_test, y_pred_test)
		### aR2
		ar2_train = adjusted_r2(y_train, y_pred_train, n_features=X_train.shape[1])
		ar2_test = adjusted_r2(y_test, y_pred_test, n_features=X_test.shape[1])

		## combine in dataframes
		## from the training dataset
		metrics_global_train_df = pd.DataFrame({
			'RMSE': [round(rmse_train, digits)], 
			'MSE': [round(mse_train, digits)], 
			'SMAPE': [round(smape_train, digits)], 
			'MAPE': [round(mape_train, digits)], 
			'MAE': [round(mae_train, digits)], 			
			'R2': [round(r2_train, digits)], 
			'aR2': [round(ar2_train, digits)],
			})
		## from the testing dataset
		metrics_global_test_df = pd.DataFrame({
			'RMSE': [round(rmse_test, digits)], 
			'MSE': [round(mse_test, digits)], 
			'SMAPE': [round(smape_test, digits)],
			'MAPE': [round(mape_test, digits)],
			'MAE': [round(mae_test, digits)], 
			'R2': [round(r2_test, digits)], 
			'aR2': [round(ar2_test, digits)], 
			})

		# combine expectation and prediction from the training
		## transform numpy.ndarray into pandas.core.frame.DataFrame
		y_pred_train_df = pd.DataFrame(y_pred_train)
		## retrieve the sample index in a column
		y_train_df = y_train.reset_index().rename(columns={"index":"sample"})
		## concatenate horizontally dataframes
		combined_train_df = pd.concat(
			[y_train_df.reset_index(drop=True), 
			y_pred_train_df.reset_index(drop=True)], 
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		) 
		## rename labels of headers
		combined_train_df.rename(columns={'phenotype': 'expectation'}, inplace=True)
		combined_train_df.rename(columns={0: 'prediction'}, inplace=True)

		# combine expectation and prediction from the testing
		## transform numpy.ndarray into pandas.core.frame.DataFrame
		y_pred_test_df = pd.DataFrame(y_pred_test)
		## retrieve the sample index in a column
		y_test_df = y_test.reset_index().rename(columns={"index":"sample"})
		## concatenate horizontally dataframes
		combined_test_df = pd.concat(
			[y_test_df.reset_index(drop=True), 
			y_pred_test_df.reset_index(drop=True)], 
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		) 
		## rename labels of headers
		combined_test_df.rename(columns={'phenotype': 'expectation'}, inplace=True)
		combined_test_df.rename(columns={0: 'prediction'}, inplace=True)

		# retrieve only prediction intervals using a custom ResidualQuantileWrapper independantly of mapie 0.9.2 to be able to manage only one sample
		## instantiate the residual quantile wrapper with the best trained model and the desired alpha level
		res_wrapper = ResidualQuantileWrapper(estimator=best_model, alpha=ALPHA)
		## fit the wrapper: trains the underlying model and calculates residual quantile for prediction intervals
		res_wrapper.fit(X_train_encoded, y_train)
		## predict on training data, returning both point predictions and prediction intervals
		y_pred_train_res_wrapper, y_intervals_train = res_wrapper.predict(X_train_encoded, return_prediction_interval=True)
		## predict on testing data, returning both point predictions and prediction intervals
		y_pred_test_res_wrapper, y_intervals_test = res_wrapper.predict(X_test_encoded, return_prediction_interval=True)
		## convert the numpy array of prediction intervals on training data into a pandas DataFrame
		## columns are named 'lower' and 'upper' for interval bounds
		y_intervals_train_df = pd.DataFrame(y_intervals_train, columns=["lower", "upper"])
		## convert the numpy array of prediction intervals on testing data into a pandas DataFrame
		y_intervals_test_df = pd.DataFrame(y_intervals_test, columns=["lower", "upper"])
		## print a message
		message_alpha = (
			"The prediction intervals (i.e., "
			+ str(round((1 - ALPHA) * 100, 1))
			+ "%) were calculated using ResidualQuantileWrapper with α = "
			+ str(ALPHA)
		)
		print(message_alpha)
		## concatenate horizontally dataframes
		### from the training dataset
		combined_train_df = pd.concat(
			[combined_train_df.reset_index(drop=True), # avoids index misalignment during concatenation
			y_intervals_train_df.reset_index(drop=True)], # avoids index misalignment during concatenation
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
		### from the testing dataset
		combined_test_df = pd.concat(
			[combined_test_df.reset_index(drop=True),  # avoids index misalignment during concatenation
			y_intervals_test_df.reset_index(drop=True)], # avoids index misalignment during concatenation
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)

		# round digits of a dataframe avoid SettingWithCopyWarning with .copy()
		## from the training dataset
		combined_train_df = combined_train_df.copy()
		numeric_cols_combined_train = combined_train_df.select_dtypes(include='number').columns
		combined_train_df[numeric_cols_combined_train] = combined_train_df[numeric_cols_combined_train].round(digits)
		## from the testing dataset
		combined_test_df = combined_test_df.copy()
		numeric_cols_combined_test = combined_test_df.select_dtypes(include='number').columns
		combined_test_df[numeric_cols_combined_test] = combined_test_df[numeric_cols_combined_test].round(digits)

		# build a clean phenotype/dataset file to reuse later
		## keep only sample identifiers and the true phenotype value
		simplified_train_df = combined_train_df[["sample", "expectation"]].copy()
		simplified_test_df  = combined_test_df[["sample", "expectation"]].copy()
		## annotate dataset origin
		simplified_train_df["dataset"] = "training"
		simplified_test_df["dataset"]  = "testing"
		## concatenate vertically dataframes
		simplified_train_test_df = pd.concat(
			[simplified_train_df, 
			simplified_test_df],
			ignore_index=True,
			axis=0, join="inner" # safeguards against accidental column misalignment down the line
		)
		## rename 'expectation' to 'phenotype' for clarity
		simplified_train_test_df = simplified_train_test_df.rename(
			columns={"expectation": "phenotype"}
		).copy()
		## make sure sample identifiers are unique and sorted, then reset index
		simplified_train_test_df = (
			simplified_train_test_df
			.sort_values("sample")
			.reset_index(drop=True)
		)


















I am not satisfied by mapie behavior because 1/ it cannot estimate PIs only for one samples, and 2/ it does not provide stable and valid PIs when the amount of samples is low together with low alpha.

Consequently I would like to replace the mapie method estimating PIs by a method for single-sample uncertainty estimations (prediction intervals, confidance intervals, or another uncertainty metrics) which would by 1/ highly compatible with sklearn, 3/ compatible with many kind of regressors, 3/ recognized as robust, 4/ easy to implement, and 5/ not computationally intensive.

Let me show two blocks using mapie before to recommand me a method for single-sample uncertainty estimations fitting well my context and objectives.

# From the modeling subcommand
		# perform prediction
		## from the training dataset
		y_pred_train = best_model.predict(X_train_encoded)
		## from the testing dataset
		y_pred_test = best_model.predict(X_test_encoded)
		# combine expectation and prediction from the training
		## transform numpy.ndarray into pandas.core.frame.DataFrame
		y_pred_train_df = pd.DataFrame(y_pred_train)
		## retrieve the sample index in a column
		y_train_df = y_train.reset_index().rename(columns={"index":"sample"})
		## concatenate horizontally dataframes
		combined_train_df = pd.concat(
			[y_train_df.reset_index(drop=True), 
			y_pred_train_df.reset_index(drop=True)], 
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		) 
		## rename labels of headers
		combined_train_df.rename(columns={'phenotype': 'expectation'}, inplace=True)
		combined_train_df.rename(columns={0: 'prediction'}, inplace=True)

		# combine expectation and prediction from the testing
		## transform numpy.ndarray into pandas.core.frame.DataFrame
		y_pred_test_df = pd.DataFrame(y_pred_test)
		## retrieve the sample index in a column
		y_test_df = y_test.reset_index().rename(columns={"index":"sample"})
		## concatenate horizontally dataframes
		combined_test_df = pd.concat(
			[y_test_df.reset_index(drop=True), 
			y_pred_test_df.reset_index(drop=True)], 
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		) 
		## rename labels of headers
		combined_test_df.rename(columns={'phenotype': 'expectation'}, inplace=True)
		combined_test_df.rename(columns={0: 'prediction'}, inplace=True)

		# retrieve only prediction intervals with mapie 0.8.2
		## initialize mapie wrapper around the best_model
		mapie = mp.regression.MapieRegressor(
			estimator=best_model,
			method="plus", # or "minmax", "naive" depending on your needs
			cv="prefit" # because model is already trained
		)
		## fit mapie on training data without predict_params (needed in mapie 0.9.2 but not recognized by regressors)
		mapie.fit(
			X_train_encoded,
			np.zeros(len(X_train_encoded)) # dummy targets required but ignored in "prefit"
		)
		## calculate the [(1 - α) * 100]% prediction intervals only ("_," rather than together with point predictions) without return_pred_int argument (specific to mapie 0.9.2) and get a 3D numpy array of shape (lower bound and upper bound)
		_, y_intervals_train_nda = mapie.predict(X_train_encoded, alpha=ALPHA)
		_, y_intervals_test_nda = mapie.predict(X_test_encoded, alpha=ALPHA)
		## print a message
		message_alpha = "The prediction intervals (i.e., " + str(((1-ALPHA)*100)) + "%) were calculated using a significance level of α = " + str(ALPHA)
		print(message_alpha)
		## transform 3D numpy.ndarray into pandas.core.frame.DataFrame
		### check shape of the numpy.ndarray ### print(y_intervals_train_nda.shape) # (n_samples, 2, 1)
		### remove singleton dimension to get a shape (n_samples, 2), where [:, 0] is lower and [:, 1] is upper 
		y_intervals_train_squeezed_nda = np.squeeze(y_intervals_train_nda, axis=2)
		y_intervals_test_squeezed_nda = np.squeeze(y_intervals_test_nda, axis=2)
		### build the pandas.core.frame.DataFrame
		y_intervals_train_df = pd.DataFrame(
			y_intervals_train_squeezed_nda, # shape (n_samples, 2)
			columns=["lower", "upper"]
		)
		y_intervals_test_df = pd.DataFrame(
			y_intervals_test_squeezed_nda, # shape (n_samples, 2)
			columns=["lower", "upper"]
		)

		# concatenate horizontally dataframes
		## from the training dataset
		combined_train_df = pd.concat(
			[combined_train_df.reset_index(drop=True), 
			y_intervals_train_df.reset_index(drop=True)],
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
		## from the testing dataset
		combined_test_df = pd.concat(
			[combined_test_df.reset_index(drop=True), 
			y_intervals_test_df.reset_index(drop=True)],
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
# From the prediction subcommand
		# detect the loaded model and perform prediction
		## detect the loaded model
		detected_model = loaded_model.__class__.__name__
		## print a message
		message_detected_model = "The pipeline components of the provided best model were properly recognized: " + re.sub(r'\s+', ' ', str(loaded_model)).strip()
		print(message_detected_model)
		## perform prediction
		y_pred_mutations = loaded_model.predict(X_mutations_encoded)

		# prepare output results
		## transform prediction array to DataFrame
		y_pred_mutations_df = pd.DataFrame(y_pred_mutations)
		## retrieve sample identifiers and rename the column
		y_samples_df = pd.DataFrame(
			X_mutations_encoded.reset_index().iloc[:, 0]
		).rename(columns={X_mutations_encoded.reset_index().columns[0]: "sample"})
		## concatenate horizontally dataframes
		combined_mutations_df = pd.concat(
			[y_samples_df.reset_index(drop=True), 
			y_pred_mutations_df.reset_index(drop=True)],
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
		## rename prediction column
		combined_mutations_df.rename(columns={0: 'prediction'}, inplace=True)
		# retrieve prediction intervals with mapie 0.8.2 using prefit mode
		## initialize mapie wrapper with the loaded model (already trained)
		mapie = mp.regression.MapieRegressor(
			estimator=loaded_model,
			method="plus", # or "minmax", "naive"
			cv="prefit" # # because model is already trained
		)
		## refit mapie only for conformal prediction calibration using the test data
		mapie.fit(
			X_mutations_encoded,
			np.zeros(X_mutations_encoded.shape[0]) # dummy targets required but ignored in "prefit"
		)
		## calculate the [(1 - α) * 100]% prediction intervals only ("_," rather than together with point predictions) without return_pred_int argument (specific to mapie 0.9.2) to get a 3D numpy array of shape (lower bound and upper bound)
		_, y_intervals_mutations_nda = mapie.predict(X_mutations_encoded, alpha=ALPHA)
		## print a message
		message_alpha = "The prediction intervals (i.e., " + str(((1-ALPHA)*100)) + "%) were calculated using a significance level of α = " + str(ALPHA)
		print(message_alpha)
		## transform 3D numpy.ndarray into pandas.core.frame.DataFrame
		### check shape of the numpy.ndarray
		### print(y_intervals_train_nda.shape) # (n_samples, 2, 1)
		### remove singleton dimension to get a shape (n_samples, 2), where [:, 0] is lower and [:, 1] is upper
		y_intervals_mutations_squeezed = np.squeeze(y_intervals_mutations_nda, axis=2)
		## build the pandas.core.frame.DataFrame
		y_intervals_mutations_df = pd.DataFrame(
			y_intervals_mutations_squeezed,
			columns=["lower", "upper"]
		)
		
		# concatenate horizontally dataframes
		combined_mutations_df = pd.concat(
			[combined_mutations_df.reset_index(drop=True),
			y_intervals_mutations_df.reset_index(drop=True)],
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)


---------------------------------------------------------------

With the updated blocks below, the modeling and prediction subcommands works as expected and the prediction subcommand is able to calculat PIs only for one sample. Do you still see any important issues in these block

# ---------- ResidualQuantileWrapper ----------
# import numpy as np # arrays
# from sklearn.base import BaseEstimator, RegressorMixin # Import base classes from Scikit-learn to ensure compatibility with its utilities (e.g., cross-validation, cloning, pipelines)
class ResidualQuantileWrapper(BaseEstimator, RegressorMixin):
	"""
	wrapper class to compute prediction intervals based on residual quantiles
	around a fitted regression estimator
	this is a custom implementation similar in spirit to MAPIE's ResidualQuantileWrapper
	parameters
	----------
	estimator : object
		A regression estimator implementing fit and predict methods.

	alpha : float, default=0.05
		Significance level for prediction intervals (e.g., 0.05 for 95% intervals).

	prefit : bool, default=False
		If True, assumes that the estimator has already been fitted externally
		and skips refitting during wrapper training.
	"""
	def __init__(self, estimator, alpha=0.05, prefit=False):
		self.estimator = estimator      # underlying regression model
		self.alpha = alpha              # confidence level (significance)
		self.prefit = prefit            # flag to avoid retraining an already fitted model
		self.lower_quantile = None      # to store residual lower quantile threshold
		self.upper_quantile = None      # to store residual upper quantile threshold
	def fit(self, X, y):
		"""
		fit the estimator and compute residual quantiles on training (or calibration) data.
		parameters
		----------
		X : array-like of shape (n_samples, n_features)
			Training or calibration features.
		y : array-like of shape (n_samples,) or (n_samples, 1)
			Target values.
		returns
		-------
		self : object
			Returns self for chaining.
		"""
		# check that there are enough samples to estimate quantiles
		if len(X) < 2:
			raise ValueError("ResidualQuantileWrapper requires at least 2 calibration samples to compute prediction intervals.")
		# fit the underlying regression model only if not already trained
		if not self.prefit:
			self.estimator.fit(X, y)
		# ensure target is 1D to align with predicted values
		y_1d = y.squeeze() if hasattr(y, "squeeze") else np.ravel(y)
		# calculate residuals as absolute differences
		residuals = np.abs(y_1d - self.estimator.predict(X))
		# compute residual quantiles to define interval width
		self.lower_quantile = np.quantile(residuals, self.alpha / 2)
		self.upper_quantile = np.quantile(residuals, 1 - self.alpha / 2)
		# optional print/log for debugging
		print(f"[ResidualQuantileWrapper] Residual quantile bounds set to ±{self.upper_quantile:.4f} for α = {self.alpha}")
		return self
	def predict(self, X, return_prediction_interval=False):
		"""
		predict point estimates and optionally prediction intervals for new data.
		parameters
		----------
		X : array-like of shape (n_samples, n_features)
			Input features.
		return_prediction_interval : bool, default=False
			If True, also return prediction intervals (lower and upper bounds).
		returns
		-------
		y_pred : ndarray of shape (n_samples,)
			Predicted target values.
		y_pred_intervals : ndarray of shape (n_samples, 2), optional
			Prediction intervals with columns [lower, upper], returned only if
			return_prediction_interval=True.
		"""
		# compute point predictions using the underlying model
		y_pred = self.estimator.predict(X)
		if return_prediction_interval:
			# construct prediction intervals using stored residual quantiles
			lower_bounds = y_pred - self.upper_quantile
			upper_bounds = y_pred + self.upper_quantile
			prediction_intervals = np.vstack((lower_bounds, upper_bounds)).T
			return y_pred, prediction_intervals
		return y_pred  # point predictions only
	def get_params(self, deep=True):
		"""
		get parameters for this estimator. Required for sklearn compatibility.
		parameters
		----------
		deep : bool, default=True
			If True, will return the parameters for this estimator and contained subobjects.
		returns
		-------
		params : dict
			Parameter names mapped to their values.
		"""
		return {
			"estimator": self.estimator,
			"alpha": self.alpha,
			"prefit": self.prefit
		}
	def set_params(self, **params):
		"""
		set the parameters of this estimator. Required for sklearn compatibility.
		parameters
		----------
		**params : dict
			Estimator parameters.
		returns
		-------
		self : object
			Estimator instance.
		"""
		for key, value in params.items():
			setattr(self, key, value)
		return self
# Block of the modeling subcommand
		# retrieve only prediction intervals using a custom ResidualQuantileWrapper independantly of mapie 0.9.2 to be able to manage only one sample
		## instantiate the residual quantile wrapper with the best trained model and the desired alpha level
		res_wrapper = ResidualQuantileWrapper(estimator=best_model, alpha=ALPHA)
		## fit the wrapper: trains the underlying model and calculates residual quantile for prediction intervals
		res_wrapper.fit(X_train_encoded, y_train)
		## predict on training data, returning both point predictions and prediction intervals
		y_pred_train, y_intervals_train = res_wrapper.predict(X_train_encoded, return_prediction_interval=True)
		## predict on testing data, returning both point predictions and prediction intervals
		y_pred_test, y_intervals_test = res_wrapper.predict(X_test_encoded, return_prediction_interval=True)
		## convert the numpy array of prediction intervals on training data into a pandas DataFrame
		## columns are named 'lower' and 'upper' for interval bounds
		y_intervals_train_df = pd.DataFrame(y_intervals_train, columns=["lower", "upper"])
		## convert the numpy array of prediction intervals on testing data into a pandas DataFrame
		y_intervals_test_df = pd.DataFrame(y_intervals_test, columns=["lower", "upper"])
		## print a message
		message_alpha = "The prediction intervals (i.e., " + str(((1-ALPHA)*100)) + "%) were calculated using ResidualQuantileWrapper with α = " + str(ALPHA)
		print(message_alpha)
		## concatenate horizontally dataframes
		### from the training dataset
		combined_train_df = pd.concat(
			[combined_train_df.reset_index(drop=True), # avoids index misalignment during concatenation
			y_intervals_train_df.reset_index(drop=True)], # avoids index misalignment during concatenation
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
		### from the testing dataset
		combined_test_df = pd.concat(
			[combined_test_df.reset_index(drop=True),  # avoids index misalignment during concatenation
			y_intervals_test_df.reset_index(drop=True)], # avoids index misalignment during concatenation
			axis=1, join="inner" # safeguards against accidental row misalignment down the line
		)
# Block of the prediction subcommand
		# retrieve only prediction intervals using a custom ResidualQuantileWrapper independantly of mapie 0.9.2 to be able to manage only one sample
		## fit the wrapper with loaded model and calibration data
		res_wrapper = ResidualQuantileWrapper(estimator=loaded_model, alpha=ALPHA, prefit=True)
		res_wrapper.fit(X_calib, y_calib)
		## predict with prediction intervals
		y_pred_mutations, y_intervals_mutations = res_wrapper.predict(
			X_mutations_encoded,
			return_prediction_interval=True
		)
		## convert prediction intervals to DataFrame
		y_intervals_mutations_df = pd.DataFrame(
			y_intervals_mutations,
			columns=["lower", "upper"]
		)
		## print a message
		message_alpha = "The prediction intervals (i.e., " + str(((1-ALPHA)*100)) + "%) were calculated using a significance level of α = " + str(ALPHA)
		print(message_alpha)
		## concatenate intervals with predictions
		combined_mutations_df = pd.concat(
			[combined_mutations_df.reset_index(drop=True),
			y_intervals_mutations_df.reset_index(drop=True)],
			axis=1, join="inner"
		)


I tested different combinaisons of feature selection methods (SelectKBest (SKB), SelectFromModel with Lasso (laSFM), SelectFromModel with ElasticNet (enSFM), SelectFromModel with Random Forest (rfSFM), or Boruta (BO)) and model regressor (bayesian bidge (BRI), cat boost (CB), decision tree (DT), elasticnet (EN), gradient boosting (GB), hist gradient boosting (HGB), huber (HU), k-nearest neighbors (KNN), lassa (LA), light gradient goosting machine (LGBM), multi-layer perceptron (MLP), nu support vector (NSV), polynomial (PN), ridge (RI), random forest (RF), support vector regressor (SVR) or extreme gradient boosting (XGB)). For all these combinaisons I got the expected PIs for both the modeling subcommand and the prediction subcommand. I just observed a weird systhematic print in the shell only when using Boruta (BO) and my modeling subcommand, where the "The prediction intervals (i.e., 95.0%) were calculated using ResidualQuantileWrapper with α = 0.05" is not properly aligned to the left- of the shell as you can see below:
# weird print
The pipeline potentially selected and used 26 encoded features to train the model
                                                                                                                                      The prediction intervals (i.e., 95.0%) were calculated using ResidualQuantileWrapper with α = 0.05
# potential root cause
# ---------- ResidualQuantileWrapper ----------
# import numpy as np # arrays
# from sklearn.base import BaseEstimator, RegressorMixin # Import base classes from Scikit-learn to ensure compatibility with its utilities (e.g., cross-validation, cloning, pipelines)
class ResidualQuantileWrapper(BaseEstimator, RegressorMixin):
	"""
	wrapper class to compute prediction intervals based on residual quantiles
	around a fitted regression estimator
	this is a custom implementation similar in spirit to MAPIE's ResidualQuantileWrapper
	parameters
	----------
	estimator : object
		A regression estimator implementing fit and predict methods.

	alpha : float, default=0.05
		Significance level for prediction intervals (e.g., 0.05 for 95% intervals).

	prefit : bool, default=False
		If True, assumes that the estimator has already been fitted externally
		and skips refitting during wrapper training.
	"""
	def __init__(self, estimator, alpha=0.05, prefit=False):
		self.estimator = estimator      # underlying regression model
		self.alpha = alpha              # confidence level (significance)
		self.prefit = prefit            # flag to avoid retraining an already fitted model
		self.lower_quantile = None      # to store residual lower quantile threshold
		self.upper_quantile = None      # to store residual upper quantile threshold
	def fit(self, X, y):
		"""
		fit the estimator and compute residual quantiles on training (or calibration) data.
		parameters
		----------
		X : array-like of shape (n_samples, n_features)
			Training or calibration features.
		y : array-like of shape (n_samples,) or (n_samples, 1)
			Target values.
		returns
		-------
		self : object
			Returns self for chaining.
		"""
		# check that there are enough samples to estimate quantiles
		if len(X) < 2:
			raise ValueError("ResidualQuantileWrapper requires at least 2 calibration samples to compute prediction intervals.")
		# fit the underlying regression model only if not already trained
		if not self.prefit:
			self.estimator.fit(X, y)
		# ensure target is 1D to align with predicted values
		y_1d = y.squeeze() if hasattr(y, "squeeze") else np.ravel(y)
		# calculate residuals as absolute differences
		residuals = np.abs(y_1d - self.estimator.predict(X))
		# compute residual quantiles to define interval width
		self.lower_quantile = np.quantile(residuals, self.alpha / 2)
		self.upper_quantile = np.quantile(residuals, 1 - self.alpha / 2)
		# optional print/log for debugging
		#print(f"[ResidualQuantileWrapper] Residual quantile bounds set to ±{self.upper_quantile:.4f} for α = {self.alpha}")
		return self
	def predict(self, X, return_prediction_interval=False):
		"""
		predict point estimates and optionally prediction intervals for new data.
		parameters
		----------
		X : array-like of shape (n_samples, n_features)
			Input features.
		return_prediction_interval : bool, default=False
			If True, also return prediction intervals (lower and upper bounds).
		returns
		-------
		y_pred : ndarray of shape (n_samples,)
			Predicted target values.
		y_pred_intervals : ndarray of shape (n_samples, 2), optional
			Prediction intervals with columns [lower, upper], returned only if
			return_prediction_interval=True.
		"""
		# compute point predictions using the underlying model
		y_pred = self.estimator.predict(X)
		if return_prediction_interval:
			# construct prediction intervals using stored residual quantiles
			lower_bounds = y_pred - self.upper_quantile
			upper_bounds = y_pred + self.upper_quantile
			prediction_intervals = np.vstack((lower_bounds, upper_bounds)).T
			return y_pred, prediction_intervals
		return y_pred  # point predictions only
	def get_params(self, deep=True):
		"""
		get parameters for this estimator. Required for sklearn compatibility.
		parameters
		----------
		deep : bool, default=True
			If True, will return the parameters for this estimator and contained subobjects.
		returns
		-------
		params : dict
			Parameter names mapped to their values.
		"""
		return {
			"estimator": self.estimator,
			"alpha": self.alpha,
			"prefit": self.prefit
		}
	def set_params(self, **params):
		"""
		set the parameters of this estimator. Required for sklearn compatibility.
		parameters
		----------
		**params : dict
			Estimator parameters.
		returns
		-------
		self : object
			Estimator instance.
		"""
		for key, value in params.items():
			setattr(self, key, value)
		return self

# ---------- BorutaSelectorDF ----------
# import boruta as bo # BorutaPy wrapper
# import numpy as np # arrays
# import pandas as pd # DataFrame support
# import threading as th # alias for threading
# import time as ti # alias for time
# import tqdm.auto as tqa # adaptive tqdm
# from sklearn.base import BaseEstimator, TransformerMixin # base classes for custom estimators and transformers compatible with sklearn pipelines
class BorutaSelectorDF(BaseEstimator, TransformerMixin):  # subclass for sklearn compatibility
	"""
	Boruta feature selector with nested tqdm bars that keep both inner and outer bars informative.
	Compatible with sklearn Pipelines and GridSearchCV.
	"""
	""" -------------------- INIT -------------------- """
	def __init__(self, estimator, show_progress=True, **kwargs):  # constructor
		self.estimator = estimator  # base estimator used by Boruta
		self.kwargs = kwargs  # BorutaPy‑specific kwargs
		self.show_progress = show_progress  # toggle progress
		self.boruta = None  # will hold BorutaPy instance
		self.support_ = None  # mask of selected features after fit
		self.ranking_ = None  # ranking of all features after fit
		self.columns_ = None  # column names if X is a DataFrame

	""" ---------------- INTERNAL: Fit with tqdm ---------------- """
	def _fit_with_progress(self, X_np, y):  # helper: run Boruta with manual progress bar
		kwargs = self.kwargs.copy()  # copy kwargs to avoid side‑effects
		kwargs.pop("verbose", None)  # remove verbose to silence BorutaPy
		self.boruta = bo.BorutaPy(  # instantiate BorutaPy
			estimator=self.estimator,
			verbose=0,  # silence BorutaPy internal verbose
			**kwargs
		)
		total_iter = self.boruta.max_iter  # total iterations Boruta will run
		with tqa.tqdm(total=total_iter, desc="Boruta iterations",  # use tqdm.auto alias tqa
					position=1, leave=False, dynamic_ncols=True) as pbar:
			# Run Boruta fit in a separate thread to keep UI responsive
			def target():
				self.boruta.fit(X_np, y)  # actual fitting
			thread = th.Thread(target=target)  # create thread (alias th)
			thread.start()
			while thread.is_alive():  # update bar while running
				if pbar.n < total_iter:
					pbar.update(1)
				else:
					pbar.n = total_iter  # cap progress bar if exceeded
				pbar.refresh()
				ti.sleep(0.5)  # sleep (alias ti)
			thread.join()  # ensure completion

	""" -------------------- FIT -------------------- """
	def fit(self, X, y):  # standard sklearn fit
		if isinstance(X, pd.DataFrame):  # handle DataFrame input
			self.columns_ = X.columns  # save column names
			X_np = X.values  # convert to NumPy
		else:
			X_np = np.asarray(X)  # ensure NumPy

		if self.show_progress:  # choose verbose fit
			self._fit_with_progress(X_np, y)  # run with manual progress bar
		else:
			self.boruta = bo.BorutaPy(estimator=self.estimator, **self.kwargs)  # silent Boruta
			self.boruta.fit(X_np, y)  # fit without bars
		self.support_ = self.boruta.support_  # store mask
		self.ranking_ = self.boruta.ranking_  # store rankings
		return self  # return self for chaining

	""" ------------------ TRANSFORM ------------------ """
	def transform(self, X):  # reduce X to selected features
		if isinstance(X, pd.DataFrame):  # DataFrame input
			return X.loc[:, self.support_]  # mask columns
		return X[:, self.support_]  # mask NumPy array

	""" --------------- PARAMETER GETTER --------------- """
	def get_params(self, deep=True):  # expose params for grid search
		params = {"estimator": self.estimator, "show_progress": self.show_progress}  # base params
		if deep and hasattr(self.estimator, "get_params"):  # include nested estimator params
			for k, v in self.estimator.get_params().items():
				params[f"estimator__{k}"] = v  # flatten nested params
		params.update(self.kwargs)  # add BorutaPy kwargs
		return params  # return full param dict


